# レベル3: 高度なチュートリアル（120分コース）

## 🎯 目標
このチュートリアルでは、専門分野（医療知識）での高度なLoRAファインチューニングを実践し、プロダクションレベルの学習技術を習得します。

**所要時間**: 約120分  
**前提知識**: レベル1・2の完了  
**学習内容**: 専門データセット、高度なパラメータ調整、評価手法、プロダクション設定

⚠️ **注意**: このチュートリアルは教育目的のみです。医療実務での使用は適切な専門家の監督下で行ってください。

---

## 📋 事前準備

### ✅ 1. 前提知識の確認
以下を理解していることが必要です：
- LoRAパラメータ（rank, alpha, dropout）の意味
- 学習率とエポック数の影響
- 損失曲線の読み方
- オーバーフィッティングの概念

### ✅ 2. 計算リソースの確認
```bash
# システムリソースを確認
docker stats --no-stream

# メモリ使用量の確認
free -h  # Linuxの場合
# または
vm_stat | grep "Pages free\|Pages active\|Pages inactive" # macOSの場合
```

### ✅ 3. より大きなモデルの準備（オプション）
```bash
# より大きなモデルをダウンロード（時間とストレージに余裕がある場合）
docker exec llmlora-ollama ollama pull llama2:13b

# 利用可能なモデルを確認
docker exec llmlora-ollama ollama list
```

---

## 🧬 ステップ1: 専門分野データセットでの学習

### 1.1 医療専門データセットの理解
このレベルでは医療専門知識データセット（20例）を使用します：

**データセットの特徴**：
- 医学用語と診断知識
- 疾患の分類と治療法
- 薬物療法と患者管理
- 高度な専門性と正確性が要求

### 1.2 専門データセットのアップロード
1. **データセット**タブに移動
2. **「データセットをアップロード」**をクリック
3. アップロードフォームで以下を入力：
   - **ファイル**: `tutorial/datasets/level3_advanced_medical.json`
   - **名前**: "医療専門知識データセット"
   - **説明**: "医学診断と治療に関する専門的な質問応答データ"
   - **タイプ**: "指示"
4. **「アップロード」**をクリック

### 1.3 データ品質の事前分析
アップロード後、データの特性を確認：
- **平均文字数**: より長い説明文
- **専門用語密度**: 高い
- **構造の複雑性**: 診断→治療の論理的流れ

---

## ⚙️ ステップ2: 高度なLoRAパラメータ設計

### 2.1 専門分野に最適化されたLoRA設定
新しい訓練ジョブを作成：

**基本情報**：
- **ジョブ名**: "医療専門知識モデル_v1"
- **ベースモデル**: "llama2:7b"（または13bが利用可能な場合）
- **訓練データセット**: "医療専門知識データセット (20 例)"

### 2.2 カスタムLoRA設定の設計
専門分野用の**カスタム設定**を手動で作成：

**LoRA設定**：
- **ランク**: 16（高い表現力）
- **アルファ**: 32（強い適応力）
- **ドロップアウト**: 0.1（オーバーフィッティング防止）
- **対象モジュール**: q_proj, v_proj, k_proj, o_proj, gate_proj, up_proj

**🎯 設計の理由**：
- **高ランク（r=16）**: 医学用語の複雑な関係性を学習
- **高アルファ（α=32）**: 専門知識の重要性を強調
- **多モジュール**: 包括的な知識表現
- **適度なドロップアウト**: 汎化性能の確保

### 2.3 高度な訓練設定
**カスタム訓練設定**：
- **学習率**: 0.00005（慎重な学習）
- **エポック数**: 5（深い学習）
- **バッチサイズ**: 2（メモリ効率）
- **最大長**: 2048（長い医学説明文に対応）
- **ウォームアップステップ**: 10（学習の安定化）

---

## 🔬 ステップ3: 段階的学習と評価

### 3.1 第1段階: 基礎学習（エポック1-2）
**目標**: 医学用語と基本概念の学習

**監視ポイント**：
- 初期損失: ~3.0-3.5
- 目標損失: ~2.0-2.5
- 学習の安定性

### 3.2 第2段階: 深化学習（エポック3-4）
**目標**: 診断論理と治療体系の理解

**監視ポイント**：
- 中間損失: ~1.5-2.0
- 知識の統合度
- オーバーフィッティングの兆候

### 3.3 第3段階: 精密化（エポック5）
**目標**: 細かい調整と最適化

**監視ポイント**：
- 最終損失: ~1.0-1.5
- 収束の安定性
- 汎化性能の確保

**⏱️ 予想実行時間**: 約40-60分（MacBook Air M4）

---

## 📊 ステップ4: 高度な結果分析

### 4.1 学習曲線の詳細分析
**期待される学習パターン**：

```
エポック1: 3.2 → 2.8 （用語学習）
エポック2: 2.8 → 2.2 （概念理解）
エポック3: 2.2 → 1.8 （論理構築）
エポック4: 1.8 → 1.4 （精密化）
エポック5: 1.4 → 1.2 （最適化）
```

### 4.2 専門性評価指標
**定量的評価**：
- 医学用語の正確性
- 診断論理の一貫性
- 治療推奨の適切性

**定性的評価**：
- 回答の専門性レベル
- 文章の流暢性
- 安全性への配慮

### 4.3 ベンチマーク比較
| モデル | 最終損失 | 専門用語精度 | 論理一貫性 | 安全性 |
|--------|----------|--------------|-----------|--------|
| ベース | - | 低 | 中 | 中 |
| レベル1 | 1.5 | 低 | 低 | 中 |
| レベル2 | 1.0 | 中 | 中 | 中 |
| レベル3 | 1.2 | **高** | **高** | **高** |

---

## 🚀 ステップ5: プロダクション最適化

### 5.1 パフォーマンスチューニング
**第2回目の実験（最適化版）**：

**改良された設定**：
- **ジョブ名**: "医療専門知識モデル_v2_optimized"
- **ランク**: 12（効率性重視）
- **学習率**: 3e-5（安定性重視）
- **エポック数**: 4（効率的学習）

### 5.2 A/Bテストの実行
2つの異なる設定を比較：

**設定A（高表現力）**：
- ランク16、アルファ32、エポック5

**設定B（効率重視）**：
- ランク12、アルファ24、エポック4

### 5.3 最適設定の決定
以下の基準で最適設定を選択：
- 学習時間とリソース効率
- 最終的な性能指標
- 汎化性能
- メモリ使用量

---

## 💡 ステップ6: 高度な技術の実践

### 6.1 学習率スケジューリング（手動実装）
段階的に学習率を調整する実験：

**ステップ1**: 学習率0.0001で2エポック
**ステップ2**: 学習率0.00005で2エポック  
**ステップ3**: 学習率0.00001で1エポック

### 6.2 早期停止の実装概念
損失が改善しなくなった時点での停止判断：
- 連続2エポックで改善がない場合
- 損失が0.05未満の改善の場合

### 6.3 アンサンブル手法の準備
複数の異なる設定でモデルを訓練し、後で統合する準備：
- 異なるランク設定（8, 12, 16）
- 異なる学習率（5e-5, 3e-5, 1e-5）
- 異なるドロップアウト（0.05, 0.1, 0.15）

---

## 🎉 完了！マスターレベル到達

### ✅ 習得した高度なスキル
このチュートリアルで身につけたこと：

**技術的スキル**：
- [x] 専門分野データでの高度なファインチューニング
- [x] カスタムLoRAパラメータ設計
- [x] 段階的学習戦略の実装
- [x] 高度な結果分析と評価手法
- [x] プロダクション最適化技術

**専門知識**：
- [x] ドメイン固有の学習特性理解
- [x] オーバーフィッティング回避戦略
- [x] パフォーマンス vs 効率のトレードオフ
- [x] 学習プロセスの診断能力

### 🏆 達成したレベル
**LoRAマスター**: プロダクションレベルのファインチューニングが可能

**専門分野応用**: 医療、法律、技術文書など高度な専門知識の学習

**システム最適化**: リソース効率と性能のバランス調整

### 🌟 次のステップへ
これで基本から高度まで、すべてのLoRAファインチューニング技術を習得しました！

**実践的な応用**：
- 独自のデータセットでの実験
- より大きなモデル（13B, 30B）での学習
- マルチモーダル学習への拡張
- プロダクション環境での運用

---

## 🚨 高度なトラブルシューティング

### 専門的な問題解決

#### Q1: 専門用語の学習不足
**症状**: 一般的な回答になってしまう  
**対処法**:
- ランクを20-24に増やす
- 専門用語の頻度を確認
- データセットの品質を再評価

#### Q2: 学習の不安定性
**症状**: 損失が振動する  
**対処法**:
- 学習率を1e-5まで下げる
- ウォームアップステップを増やす
- グラデーションクリッピングの検討

#### Q3: メモリ不足（大規模学習）
**症状**: 最大長2048でOOMエラー  
**対処法**:
- グラデーション累積の使用
- バッチサイズを1に設定
- 最大長を1024に制限

#### Q4: 収束の遅延
**症状**: 5エポックでも高い損失  
**対処法**:
- より大きなモデル（13B）の使用
- データセットの拡張検討
- 異なるベースモデルの試行

---

## 📚 プロダクション運用への道

### 次の学習段階
1. **大規模データセット**: 100-1000例での学習
2. **マルチタスク学習**: 複数の専門分野を統合
3. **ドメイン適応**: 特定業界への特化
4. **継続学習**: モデルの継続的な改善

### 実際の応用例
- 医療診断支援システム
- 法的文書解析
- 技術文書の自動生成
- 教育コンテンツの作成

### リソースとコミュニティ
- [Hugging Face PEFT ドキュメント](https://huggingface.co/docs/peft/)
- [LoRA研究論文コレクション](../references/lora_papers.md)
- [専門分野ファインチューニング事例集](../examples/domain_specific_cases.md)

---

**🎊 マスター認定！**  
高度なLoRAファインチューニング技術を完全に習得されました。これからはプロダクションレベルでの実践的な応用に挑戦してください！

**次なる挑戦**: 独自のプロジェクトでLoRAの力を最大限に活用し、革新的なAIアプリケーションを作り出しましょう！